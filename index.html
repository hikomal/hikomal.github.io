---
layout: page
title: Enxin(Espere) Song
subtitle: master @ZJU 
use-site-title: false
---

<head>
	<style>
		a { text-decoration : none; }
		a:hover { text-decoration : underline; }
		a, a:visited { color : #b5194f; }
	</style>
	<script src="https://kit.fontawesome.com/5bef57b3e9.js" crossorigin="anonymous"></script>
</head>

<br>
Enxin Song is a master student at Zhejiang University, with <a href="https://cvnext.github.io/">CVNext Lab</a> advised by Prof. <a href="https://person.zju.edu.cn/en/gaoangwang/">Gaoang Wang</a>. She is fortunate to have internship at Media Computing Group, Microsoft Research Asia, advised by Dr. <a href="https://scholar.google.com/citations?user=Ow4R8-EAAAAJ&hl=en&oi=ao">Xun Guo</a>.Her research interests include domain adaptation, video understanding, and multi-modality learning.
<br>

<br>
<hr style="height:2px;border-width:0;color:gray;background-color:gray">
<b><i class="fa-regular fa-note-sticky" style="font-size:24px"></i> Selected Publications:</b>
<p><font color="grey" size="3">
Also see <a href="https://scholar.google.com/citations?user=sLqa-3oAAAAJ&hl=en" target="_blank">Google Scholar</a>.
</font></p>

<ul>
	<li>
		<p style="font-size:16px"> 
			<strong>
			MovieChat: From Dense Token to Sparse Memory for Long Video Understanding
			</strong>
			<br>
			<b>Enxin Song</b>, Wenhao Chai, Guanhong Wang, Yucheng Zhang, Haoyang Zhou, Feiyang Wu, Xun Guo, Tian Ye, Yan Lu, Jenq-Neng Hwang, Gaoang Wangâœ‰
			<br>
			<br>
			<a href="https://arxiv.org/abs/2307.16449">[Paper]</a>
			<a href="https://rese1f.github.io/MovieChat/">[Code]</a>
			<img alt="NPM" src="https://img.shields.io/github/stars/rese1f/MovieChat?style=social">
			<br>
			<font color="grey" size="2">
			 A novel framework that integrating vision models and LLMs to conduct long video understanding tasks. 
			</font>
	  	</p>
	</li>
	
</ul>


<br>
<hr style="height:2px;border-width:0;color:gray;background-color:gray">
<b><i class="fa-solid fa-pen-to-square" style="font-size:24px"></i> Updates:</b><br><br>
<ul>
	<li><i>Nov.2023:</i> <img src="static/imgs/microsoft.png" width="25" height="25" style="vertical-align:text-bottom"/> Become a research intern at <a href="https://www.msra.cn/">Microsoft Research Asia (MSRA)</a>, advised by principal researcher <a href="https://scholar.google.com/citations?user=Ow4R8-EAAAAJ&hl=en&oi=ao">Xun Guo</a>.
	</li><br>

	<li><i>Sept 2023:</i> <i class="fa-regular fa-note-sticky" style="font-size:20px"></i> Our paper <i>Devil in the Number: Towards Robust Multi-modality Data Filter</i> is accepted by ICCV 2023 workshop: <a href="https://www.datacomp.ai/">TNGCV-DataComp</a>.
	</li><br>
	
	<li><i>Jul.2023:</i> <i class="fa-regular fa-copy" style="font-size:20px"></i> Our project <i>MovieChat: From Dense Token to Sparse Memory in Long Video Understanding</i> is released at <a href="https://rese1f.github.io/MovieChat/">website</a>.
	</li><br>
	
	<li><i>Jun.2023:</i> <img src="static/imgs/dlut.png" width="25" height="25" style="vertical-align:text-bottom"/> I graduate from Dalian University of Technology.
	</li><br>

	<li><i>Oct.2022:</i> Start my research on domain adaptation task for image caption, advised by Professor <a href="https://person.zju.edu.cn/en/gaoangwang/">Gaoang Wang</a>.
	</li><br>

</ul>
